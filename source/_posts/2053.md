---
title: "对爬虫采集器的认知"
date: 2020-12-14 10:27:35
---

网络爬虫通过统一资源定位符URL (Uniform ResourceLocator)来查找目标网页，将用户所关注的数据内容直接返回给用户，并不需要用户以浏览网页的形式去获取信息，为用户节省了时间和精力，并提高了数据采集的准确度，使用户在海量数据中游刃有余。网络爬虫的最终目的就是从网页中获取自己所需的信息。一些爬虫基本库可以开发一个爬虫程序，获取到所需的内容，但是所有的爬虫程序都以这种方式进行编写，工作量未免太大了些，所有才有了爬虫框架。使用爬虫框架可以大大提高效率，缩短开发时间。

![undefined](http://openluat-luatcommunity.oss-cn-hangzhou.aliyuncs.com/images/20201214102340268_wx_article_20190206222137_gsdv1M.jpg "undefined")

当下是大数据时代，在这个信息爆炸的时代，我们可以利用爬虫获取大量有价值的数据，通过数据分析获得更多隐性的有价值的规律。

用途广泛。针对电商来说，抓取各种商品信息就可以做到精细化运营，精准营销。对新闻资讯平台和搜索引擎来说，抓取其他平台原创新闻稿，进行热点分析，就可以合理筛选优质内容，打造更有价值的新闻平台。（还可以抓取车票、爬取论文素材等等。已经与我们的生活结合在一起了。）
### 通用爬虫
通用网络爬虫 是 捜索引擎抓取系统（Baidu、Google、Yahoo等）的重要组成部分。主要目的是将互联网上的网页下载到本地，形成一个互联网内容的镜像备份。
### 聚焦爬虫
聚焦爬虫，是"面向特定主题需求"的一种网络爬虫程序，它与通用搜索引擎爬虫的区别在于： 聚焦爬虫在实施网页抓取时会对内容进行处理筛选，尽量保证只抓取与需求相关的网页信息。



